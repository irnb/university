# ูุจุงุญุซ ุฏุฑ ุนููู ฺฉุงููพูุชุฑ ๐

ุงู ุฏูุฑู ุจุง ุชุดุฎุต ุงุณุชุงุฏ ูุชูุงูุฏ ุจุง ุชูุฑฺฉุฒ ุจุฑ ุฑู ฺฉ ูุจุญุซ ุฎุงุต ุงุฒ ุนููู ฺฉุงููพูุชุฑ ุจุงุดุฏ ู ุฏูุฑู ูุง ุจุง ุชุดุฎุต ุงุณุชุงุฏ ุจุง ุชูุฑฺฉุฒ ุจุฑ ููุด ูุตููุน ู ุงุฏฺฏุฑ ูุงุดู ุฎูุงูุฏ ุจูุฏ.

## ุงุทูุงุนุงุช ุฏูุฑู ๐

- ๐จโ๐ซ ูุฏุฑุณ: ุงุณุชุงุฏ ูุฑุฎุงู
- ๐ ฺฉุชุงุจ ุฑูุฑูุณ: Beginning Deep Learning with TensorFlow (Liangqu Long, Xianming Zeng)


## ุชูุฑู ุงูู: ูพุฑุณูพุชุฑูู ๐ค

The perceptron is a type of machine learning algorithm for **supervised learning** of **binary classifiers**.


### ูุณุฆูู ๐

ูุฑุถ ฺฉูุฏ ฺฉ ูุฌููุนู ุฏุงุฏู ุดุงูู ฺูุงุฑ ููุทู ุฏูโุจูุนุฏ ุฏุงุฑู ฺฉู ุจุงุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ูพุฑุณูพุชุฑูู ุฏุฑ ุงุฏฺฏุฑ ูุงุดู ูุธุงุฑุชโุดุฏู ุทุจููโุจูุฏ ุดููุฏ.

**ฺฉูุงุณ ูุซุจุช (+1):**
- $p_1 = (2, 3)$, $y_1 = +1$
- $p_2 = (3, 5)$, $y_2 = +1$

**ฺฉูุงุณ ููู (-1):**
- $p_3 = (-1, -1)$, $y_3 = -1$
- $p_4 = (-2, -3)$, $y_4 = -1$

ูุฏู ูุง ูพุฏุง ฺฉุฑุฏู ูุฒูโูุง ($w$) ู ุจุงุงุณ ($b$) ูพุฑุณูพุชุฑูู ุงุณุช ฺฉู ุจุชูุงูุฏ ุงู ููุงุท ุฑุง ุจู ุฏุฑุณุช ุทุจููโุจูุฏ ฺฉูุฏ.

---

### ุฑุงูโุญู ุจุง ูุญุงุณุจุงุช ุฑุงุถ โ๏ธ

1. **ููุฏุงุฑุฏู ุงููู:**

   w = [0, 0], b = 0

2. **ุงูฺฏูุฑุชู ูพุฑุณูพุชุฑูู:**

   ุงูฺฏูุฑุชู ูพุฑุณูพุชุฑูู ุจู ุตูุฑุช ุชฺฉุฑุงุฑ ูุฒูโูุง ู ุจุงุงุณ ุฑุง ุจูโุฑูุฒุฑุณุงู ูโฺฉูุฏ ุชุง ุฒูุงู ฺฉู ุชูุงู ููุงุท ุจู ุฏุฑุณุช ุทุจููโุจูุฏ ุดููุฏ.

3. **ูุงููู ุจูโุฑูุฒุฑุณุงู:**

   w_new = w_old + y_i * x_i
   
   b_new = b_old + y_i

4. **ุชฺฉุฑุงุฑูุง:**

   **ุชฺฉุฑุงุฑ ุงูู:**

   - **ููุทู pโ:**

     output = sign(wยทxโ + b) = sign(0 + 0) = 0

     ฺูู 0 โ yโุ ูุงุฒ ุจู ุจูโุฑูุฒุฑุณุงู ุฏุงุฑู.

     w = [0, 0] + 1 * [2, 3] = [2, 3]
     
     b = 0 + 1 = +1

   - **ููุทู pโ:**

     output = sign(wยทxโ + b) = sign(2ร3 + 3ร5 + 1) = sign(22) = +1

     ุฏุฑุณุช ุทุจููโุจูุฏ ุดุฏู ุงุณุช.

   - **ููุทู pโ:**

     output = sign(wยทxโ + b) = sign(2ร(-1) + 3ร(-1) + 1) = sign(-4) = -1

     ุฏุฑุณุช ุทุจููโุจูุฏ ุดุฏู ุงุณุช.

   - **ููุทู pโ:**

     output = sign(wยทxโ + b) = sign(2ร(-2) + 3ร(-3) + 1) = sign(-12) = -1

     ุฏุฑุณุช ุทุจููโุจูุฏ ุดุฏู ุงุณุช.

ุชูุงู ููุงุท ุจู ุฏุฑุณุช ุทุจููโุจูุฏ ุดุฏูุฏุ ุจูุงุจุฑุงู ุงูฺฏูุฑุชู ูุชููู ูโุดูุฏ.

---

### ูุชุฌู ๐ฏ

ูุฒูโูุง ููุง:
w = [2, 3]

ุจุงุงุณ ููุง:
b = +1

---

### ฺฉุฏ ูพุงุชูู ๐ป

```python
import numpy as np

# ุฏุงุฏูโูุง ู ุจุฑฺุณุจโูุง
X = np.array([[2, 3],
              [3, 5],
              [-1, -1],
              [-2, -3]])
y = np.array([1, 1, -1, -1])

# ููุฏุงุฑุฏู ุงููู ูุฒูโูุง ู ุจุงุงุณ
w = np.zeros(2)
b = 0
learning_rate = 1

# ุงูฺฏูุฑุชู ูพุฑุณูพุชุฑูู
for epoch in range(10):
    errors = 0
    for xi, target in zip(X, y):
        output = np.sign(np.dot(w, xi) + b)
        if output != target:
            w += learning_rate * target * xi
            b += learning_rate * target
            errors += 1
    if errors == 0:
        break

print("ูุฒูโูุง ููุง:", w)
print("ุจุงุงุณ ููุง:", b)
```

## ุชูุฑู ุฏูู: MLP ๐ง
(ุฏุฑ ุญุงู ุชฺฉูู...)

## ฺฉููุฑุงูุณ: Practical AI ๐ค

- ๐ NotebookLM
- ๐ฌ LocalLLM (LMStudio, LAMA, API)
- ๐ OpenAI Standard API 
- ๐จ Image Generation (Photo AI Idea)